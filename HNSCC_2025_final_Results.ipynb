{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kajal.panchal/kajal/kajal/tools/miniconda3/install_loc/envs/HNSCC/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "# Importing all necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing os module\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "#import shap\n",
    "import shap\n",
    "import random\n",
    "import scipy.stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split Function: Splits the data into train and test\n",
    "\n",
    "x: input\n",
    "\n",
    "y:output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x, y, random_state): # x and y are raw\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=random_state)\n",
    "    # data without imputation and target values\n",
    "    return x_train, x_test, y_train, y_test # _0 retaines sample type information _1 are without sample type info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Selection: randomly selects a set of n features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection(num, all_features, random_state):\n",
    "    # num is the feature set size to be selected\n",
    "    # all_features = total pool of features\n",
    "    # random selection of columns\n",
    "    random.seed(random_state)\n",
    "    features = []\n",
    "    features = random.sample(all_features, num)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Min-Max Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaling(x_train, x_test):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "    x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns, index=x_test.index)\n",
    "    return x_train, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(x_train, x_test):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    imputer.fit(x_train)\n",
    "    x_train = pd.DataFrame(imputer.transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "    x_test = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns, index=x_test.index)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label = \"Tumor\")\n",
    "    precision = precision_score(y_true,y_pred, pos_label = \"Tumor\")\n",
    "    recall = recall_score(y_true, y_pred, pos_label = \"Tumor\")\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return acc, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOXplot for model performance for selected vs random geneset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_boxplot(df_measure_imp, df_measure_random, filepath, title):\n",
    "    df_imp_long = df_measure_imp.melt(var_name=\"Model\", value_name=\"Accuracy\")\n",
    "    df_imp_long[\"Type\"] = \"Important\"\n",
    "    df_rand_long = df_measure_random.melt(var_name=\"Model\", value_name=\"Accuracy\")\n",
    "    df_rand_long[\"Type\"] = \"Random\"\n",
    "    df_all = pd.concat([df_imp_long, df_rand_long], ignore_index= True)\n",
    "\n",
    "    # calculating p-val\n",
    "    p_cv_logr = float(scipy.stats.wilcoxon(df_measure_imp[\"LogR\"], df_measure_random[\"LogR\"],alternative = \"greater\")[1])\n",
    "    #print(p_cv_logr)\n",
    "    p_cv_RF = float(scipy.stats.wilcoxon(df_measure_imp[\"RF\"], df_measure_random[\"RF\"], alternative = \"greater\")[1])\n",
    "    #print(p_cv_RF)\n",
    "    p_cv_MLP = float(scipy.stats.wilcoxon(df_measure_imp[\"MLP\"], df_measure_random[\"MLP\"], alternative = \"greater\")[1])\n",
    "    #print(p_cv_MLP)\n",
    "    p_cv_SVC = float(scipy.stats.wilcoxon(df_measure_imp[\"SVC\"], df_measure_random[\"SVC\"], alternative = \"greater\")[1])\n",
    "    #print(p_cv_SVC)\n",
    "    pvals = {\"LogR\":p_cv_logr, \"RF\":p_cv_RF, \"MLP\":p_cv_MLP, \"SVC\": p_cv_SVC}\n",
    "    plt.figure(figsize=(10,7))\n",
    "    ax = sns.boxplot(x=\"Model\", y=\"Accuracy\", hue=\"Type\", data=df_all, palette=\"Set2\")\n",
    "\n",
    "    # Add p-values above boxes\n",
    "    for i, model in enumerate(df_all[\"Model\"].unique()):\n",
    "        y = df_all[df_all[\"Model\"]==model][\"Accuracy\"].max() + 0.002  # position above box\n",
    "        p = pvals[model]\n",
    "        ax.text(i, y, f\"p = {p:.3e}\", ha=\"center\", va=\"bottom\", fontsize=10, color=\"black\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(title=\"Gene Set\")  \n",
    "    plt.savefig(filepath,  dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_task(x_train, x_test, y_train, y_test, models, model_names, random_state):\n",
    "        \n",
    "        # accuracy dictionary\n",
    "        accuracy_cv = {} # iteration over seeds\n",
    "        accuracy_pred = {} # iteration over seeds\n",
    "      \n",
    "        i = 0\n",
    "        for est in models: \n",
    "                model_name = model_names[i]\n",
    "                i = i + 1\n",
    "                est = est.fit(x_train, y_train)\n",
    "\n",
    "                #  Stratified Cross validation\n",
    "                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "                y_pred_CV = cross_val_predict(est, x_train, y_train, cv=cv)               \n",
    "                report_CV = classification_report(y_train, y_pred_CV, target_names=[\"Normal\", \"Tumor\"], output_dict=True)\n",
    "                acc = report_CV[\"accuracy\"]\n",
    "                accuracy_cv[model_name] = acc\n",
    "\n",
    "\n",
    "                # prediction\n",
    "                y_pred = est.predict(x_test)\n",
    "\n",
    "                report = classification_report(y_test, y_pred, target_names=[\"Normal\", \"Tumor\"], output_dict=True)\n",
    "                acc = report[\"accuracy\"]\n",
    "                accuracy_pred[model_name] = acc\n",
    "                # returns directory for models\n",
    "        return accuracy_cv, accuracy_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification on final geneset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_miscores(X, y, random_state):\n",
    "    mi_scores = mutual_info_classif(X, y, random_state=random_state)\n",
    "    return mi_scores\n",
    "def get_migenes(x, y, k, random_state):\n",
    "    mi_df  = pd.DataFrame(columns=[\"gene\", \"MI_score\"])\n",
    "    mi_df[\"gene\"] = x.columns\n",
    "    random.seed(random_state)\n",
    "    seeds = random.sample(range(0, 1000), 3)\n",
    "    for seed in seeds: # you can increase the list of seeds\n",
    "        mi_scores= get_miscores(x, y, random_state=seed)\n",
    "        mi_df[seed] = mi_scores\n",
    "        # Mi_score column is mean of all seeds\n",
    "    mi_df[\"MI_score\"] = mi_df.iloc[:, 1:4].mean(axis=1)\n",
    "\n",
    "    mi_df = mi_df.sort_values(by=\"MI_score\", ascending=False)\n",
    "        \n",
    "    top_1000_df = mi_df.head(k)\n",
    "    top_genes_mi = mi_df[\"gene\"].tolist()[:k]\n",
    "    \n",
    "    # returns the list and dataframe\n",
    "    return top_genes_mi, top_1000_df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: RF-SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFSFM(x_train, x_test,y_train, y_test, random_state):\n",
    "    # Using RandomForestClassifier as the estimator\n",
    "    rf = RandomForestClassifier(n_estimators=500, random_state=random_state)\n",
    "    # Using SelectFromModel to select top 100 features\n",
    "    selector = SelectFromModel(rf, max_features=100, threshold=\"median\")\n",
    "    selector.fit(x_train, y_train)\n",
    "    selected_features = x_train.columns[selector.get_support()]\n",
    "    x_train_rf = x_train[selected_features]\n",
    "    x_test_rf = x_test[selected_features]\n",
    "    return x_train_rf, x_test_rf, selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: SVMRFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_rfe(x_train, y_train, features, random_state): # returns dataframe of features \n",
    "    # min = min numbers of features to be selected\n",
    "    \n",
    "    # cross validation to be used in RFECV\n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = random_state)\n",
    "    \n",
    "    # using SVC estimator to check Features importance using RFE \n",
    "    svc = svm.SVC(kernel = \"linear\", random_state=random_state)\n",
    "    # RFECV optimizes the minimum set of features needed for cassification task\n",
    "    rfecv_SVM = RFECV(svc, min_features_to_select = 20, cv=cv, scoring='f1_weighted',  n_jobs=-1)\n",
    "    fit_rfecv_SVM = rfecv_SVM.fit(x_train, y_train)\n",
    "    \n",
    "    RFECV_SVM_Top_Feat_df = pd.DataFrame({'Features': features, 'Selected': fit_rfecv_SVM.support_,\n",
    "                                  'Rank': fit_rfecv_SVM.ranking_})\n",
    "    RFECV_SVM_Top_Feat_df = RFECV_SVM_Top_Feat_df.sort_values(by = 'Rank')\n",
    " \n",
    "    return RFECV_SVM_Top_Feat_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot ROC curve\n",
    "def roc(model_list, x_test, y_test):\n",
    "    disp = RocCurveDisplay.from_estimator(model_list[0], x_test, y_test, pos_label='Tumor', name =\"LogR\", lw = 5)\n",
    "    RocCurveDisplay.from_estimator(model_list[1], x_test, y_test, pos_label='Tumor', ax=disp.ax_, name =\"RF\", lw = 5);\n",
    "    RocCurveDisplay.from_estimator(model_list[2], x_test, y_test, pos_label='Tumor', ax=disp.ax_, name =\"MLP\", lw = 5);\n",
    "    RocCurveDisplay.from_estimator(model_list[3], x_test, y_test, pos_label='Tumor', ax=disp.ax_, name =\"SVC\", lw = 5); \n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.rc(\"font\", size = 20)\n",
    "    plt.legend(fontsize = \"16\", frameon = False)\n",
    "    plt.title(\"100 genes (ANOVA)\")\n",
    "    plt.savefig(\"00-1_ROC_Top_100_Cancer.png\", dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the genes selected in SVMRFE step\n",
    "genes_r = pd.read_csv(\"results/SO/R/00-1_SVMRFE_GENEFreq_R.csv\", index_col=0)\n",
    "genes_r = list(genes_r.head(20).index)\n",
    "genes_m = pd.read_csv(\"results/SO/M/00-1_SVMRFE_GENEFreq.csv\", index_col=0)\n",
    "genes_m = list(genes_m.head(20).index)\n",
    "genes_p = pd.read_csv(\"results/SO/P/00-1_SVMRFE_GENEFreq_P.csv\", index_col=0)\n",
    "genes_p = list(genes_p.head(20).index)\n",
    "genes_pp = pd.read_csv(\"results/SO/PP/00-1_SVMRFE_GENEFreq_PP.csv\", index_col=0)\n",
    "genes_pp = list(genes_pp.head(20).index)\n",
    "genes_MO = pd.read_csv(\"results/MO/00-1_SVMRFE_GENEFreq_MO.csv\", index_col=0)\n",
    "genes_MO = list(genes_MO.head(20).index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HPX', 'SERPINA6', 'ETFDH', 'NOSTRIN', 'SERPINA1', 'SH3BGRL2', 'ORM2', 'SERPING1', 'SERPINA7', 'ASPA', 'IFI35', 'SERPINA3', 'LOC105373265', 'PID1', 'ADAM12', 'LYVE1', 'QARS', 'MMRN1', 'TRPM6', 'AGT']\n"
     ]
    }
   ],
   "source": [
    "# Remove \"_\" and anything before it from each elemets in genes_MO\n",
    "\n",
    "genes_MOwo = [gene.split(\"_\", 1)[-1] for gene in genes_MO]\n",
    "print(genes_MOwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_task_modified(x_train, x_test, y_train, y_test, models, model_names, random_state, omics):\n",
    "        \n",
    "        # accuracy dictionary\n",
    "        accuracy_cv = {} # iteration over seeds\n",
    "        accuracy_pred = {} # iteration over seeds\n",
    "\n",
    "        shap_values = {}\n",
    "        i = 0\n",
    "        for est in models: \n",
    "                model_name = model_names[i]\n",
    "                i = i + 1\n",
    "                est = est.fit(x_train, y_train)\n",
    "\n",
    "                #  Stratified Cross validation\n",
    "                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "                y_pred_CV = cross_val_predict(est, x_train, y_train, cv=cv)               \n",
    "                report_CV = classification_report(y_train, y_pred_CV, target_names=[\"Normal\", \"Tumor\"], output_dict=True)\n",
    "                acc = report_CV[\"accuracy\"]\n",
    "                accuracy_cv[model_name] = acc\n",
    "\n",
    "\n",
    "                # prediction\n",
    "                y_pred = est.predict(x_test)\n",
    "\n",
    "                report = classification_report(y_test, y_pred, target_names=[\"Normal\", \"Tumor\"], output_dict=True)\n",
    "                acc = report[\"accuracy\"]\n",
    "                accuracy_pred[model_name] = acc\n",
    "                \n",
    "                \n",
    "        return accuracy_cv, accuracy_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to be used\n",
    "def final_classification(x,y,features, omics):\n",
    "    print(\"Starting final classification for\", omics)\n",
    "    print (\"--------------------------------\")\n",
    "\n",
    "    x = x[features]\n",
    "\n",
    "    dict_acc_cv = {\"LogR\":[], \"RF\":[], \"MLP\":[], \"SVC\":[]}\n",
    "    dict_acc_pred = {\"LogR\":[], \"RF\":[], \"MLP\":[], \"SVC\":[]}\n",
    "   \n",
    "    for i in range(10):\n",
    "        print(\"Iteration:\", i+1)\n",
    "        random_state = i\n",
    "        # split the data\n",
    "        x_train, x_test, y_train, y_test = split(x, y, random_state)\n",
    "        \n",
    "        \n",
    "        if omics != \"Transcriptomics\":\n",
    "            # imputation\n",
    "            x_train, x_test = impute(x_train, x_test)\n",
    "\n",
    "        # scaling\n",
    "        x_train, x_test = minmax_scaling(x_train, x_test)\n",
    "    \n",
    "\n",
    "        \n",
    "        logr = LogisticRegression(random_state=random_state, max_iter=800, solver='liblinear')\n",
    "        rf = RandomForestClassifier(random_state=random_state, n_estimators=500)\n",
    "        mlp = MLPClassifier(random_state=random_state, max_iter=800, activation=\"relu\", solver='lbfgs', alpha=1e-5)\n",
    "        svc = SVC(random_state=random_state, kernel = \"linear\", C = 0.1)\n",
    "\n",
    "        models = [logr, rf, mlp, svc]\n",
    "        model_names = [\"LogR\", \"RF\", \"MLP\", \"SVC\"]\n",
    "    \n",
    "        acc_cv, acc_pred = classification_task_modified(x_train, x_test, y_train, y_test, models, model_names, random_state, omics)    \n",
    "        for key in acc_cv.keys():\n",
    "            dict_acc_cv[key].append(acc_cv[key])\n",
    "        for key in acc_pred.keys():\n",
    "            dict_acc_pred[key].append(acc_pred[key])\n",
    "            print(f\"Accuracy for model {key}: {acc_pred[key]}\")\n",
    "        \n",
    "\n",
    "        df_acc_cv = pd.DataFrame(dict_acc_cv)\n",
    "        df_acc_cv.to_csv(f\"results/top20_accuracy_cv_{omics}.csv\")\n",
    "\n",
    "       \n",
    "        df_acc_pred = pd.DataFrame(dict_acc_pred)\n",
    "        df_acc_pred.to_csv(f\"results/top20_accuracy_pred_{omics}.csv\")\n",
    "\n",
    "       \n",
    "\n",
    "    return df_acc_cv, df_acc_pred\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv(\"data/processed/RNAseq_processed.csv\", index_col=0)\n",
    "data_m = pd.read_csv(\"data/processed/Methylation_processed.csv\", index_col=0)\n",
    "data_p = pd.read_csv(\"data/processed/Proteomics_processed.csv\", index_col=0)\n",
    "data_pp = pd.read_csv(\"data/processed/Phosphoproteomics_processed.csv\", index_col=0)\n",
    "data_mo = pd.read_csv(\"data/processed/All_processed.csv\", index_col=0)\n",
    "x_r = data_r.drop(columns=[\"Sample_Type\"])\n",
    "y_r = data_r[\"Sample_Type\"]\n",
    "x_m = data_m.drop(columns=[\"Sample_Type\"])\n",
    "y_m = data_m[\"Sample_Type\"]\n",
    "x_p = data_p.drop(columns=[\"Sample_Type\"])\n",
    "y_p = data_p[\"Sample_Type\"]\n",
    "x_pp = data_pp.drop(columns=[\"Sample_Type\"])\n",
    "y_pp = data_pp[\"Sample_Type\"]\n",
    "x_mo = data_mo.drop(columns=[\"PP_Sample_Type\"])\n",
    "y_mo = data_mo[\"PP_Sample_Type\"]\n",
    "\n",
    "# df_r_acc_cv, df_r_acc_pred = final_classification(x_r, y_r, genes_r, \"Transcriptomics\")\n",
    "# df_m_acc_cv, df_m_acc_pred= final_classification(x_m, y_m, genes_m, \"Methylation\")\n",
    "# df_p_acc_cv, df_p_acc_pred = final_classification(x_p, y_p, genes_p, \"Proteomics\")\n",
    "# df_pp_acc_cv, df_pp_acc_pred= final_classification(x_pp, y_pp, genes_pp, \"Phosphoproteomics\")\n",
    "# df_mo_acc_cv, df_mo_acc_pred = final_classification(x_mo, y_mo, genes_MO, \"Multiomics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162, 32298), (144, 3728), (172, 9659), (172, 6342), (131, 52024))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_r.shape, data_m.shape, data_p.shape, data_pp.shape, data_mo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe of all accuracies cv column = omics types\n",
    "#values will be mean +- std dev\n",
    "df_all = pd.DataFrame()\n",
    "df_all[\"Transcriptomics\"] = df_r_acc_pred.mean().round(3).astype(str) + \" ± \" + df_r_acc_pred.std().round(3).astype(str)\n",
    "df_all[\"Methylation\"] = df_m_acc_pred.mean().round(3).astype(str) + \" ± \" + df_m_acc_pred.std().round(3).astype(str)\n",
    "df_all[\"Proteomics\"] = df_p_acc_pred.mean().round(3).astype(str) + \" ± \" + df_p_acc_pred.std().round(3).astype(str)\n",
    "df_all[\"Phosphoproteomics\"] = df_pp_acc_pred.mean().round(3).astype(str) + \" ± \" + df_pp_acc_pred.std().round(3).astype(str)\n",
    "df_all[\"Multiomics\"] = df_mo_acc_pred.mean().round(3).astype(str) + \" ± \" + df_mo_acc_pred.std().round(3).astype(str)\n",
    "df_all.to_csv(\"results/Final_Accuracies_top20_all_omics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcriptomics</th>\n",
       "      <th>Methylation</th>\n",
       "      <th>Proteomics</th>\n",
       "      <th>Phosphoproteomics</th>\n",
       "      <th>Multiomics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>0.997 ± 0.01</td>\n",
       "      <td>0.993 ± 0.015</td>\n",
       "      <td>0.991 ± 0.014</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.997 ± 0.01</td>\n",
       "      <td>0.997 ± 0.011</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "      <td>0.991 ± 0.014</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.997 ± 0.01</td>\n",
       "      <td>0.952 ± 0.044</td>\n",
       "      <td>0.991 ± 0.014</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.997 ± 0.01</td>\n",
       "      <td>0.983 ± 0.018</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "      <td>1.0 ± 0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transcriptomics    Methylation     Proteomics Phosphoproteomics  \\\n",
       "LogR    0.997 ± 0.01  0.993 ± 0.015  0.991 ± 0.014         1.0 ± 0.0   \n",
       "RF      0.997 ± 0.01  0.997 ± 0.011      1.0 ± 0.0     0.991 ± 0.014   \n",
       "MLP     0.997 ± 0.01  0.952 ± 0.044  0.991 ± 0.014         1.0 ± 0.0   \n",
       "SVC     0.997 ± 0.01  0.983 ± 0.018      1.0 ± 0.0         1.0 ± 0.0   \n",
       "\n",
       "     Multiomics  \n",
       "LogR  1.0 ± 0.0  \n",
       "RF    1.0 ± 0.0  \n",
       "MLP   1.0 ± 0.0  \n",
       "SVC   1.0 ± 0.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HNSCC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
